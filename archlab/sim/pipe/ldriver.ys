#######################################################################
# Test for copying block of size 63;
#######################################################################
	.pos 0
main:	irmovq Stack, %rsp  	# Set up stack pointer

	# Set up arguments for copy function and then invoke it
	irmovq $63, %rdx		# src and dst have 63 elements
	irmovq dest, %rsi	# dst array
	irmovq src, %rdi	# src array
	call ncopy		 
	halt			# should halt with num nonzeros in %rax
StartFun:
#/* $begin ncopy-ys */
##################################################################
# ncopy.ys - Copy a src block of len words to dst.
# Return the number of positive words (>0) contained in src.
#
# Include your name and ID here.
#
# Describe how and why you modified the baseline code.
#
##################################################################
# Do not modify this portion
# Function prologue.
# %rdi = src, %rsi = dst, %rdx = len
ncopy:

##################################################################
# You can modify this portion
	# Loop header
    iaddq $-9,%rdx       #length - 6 
	jl end		# limit < 0? if so, goto end:
Loop:	
# read val from src...
    mrmovq (%rdi),   %rcx	
    mrmovq 8(%rdi),  %r8
    mrmovq 16(%rdi), %r9
    mrmovq 24(%rdi), %r10
    mrmovq 32(%rdi), %r11
    mrmovq 40(%rdi), %r12 
    mrmovq 48(%rdi), %r13 
    mrmovq 56(%rdi), %r14 
    mrmovq 64(%rdi), %rbx  

# ...and store it to dst
    rmmovq %rcx, (%rsi)
    rmmovq %r8, 8(%rsi)
    rmmovq %r9, 16(%rsi)
    rmmovq %r10, 24(%rsi)
    rmmovq %r11, 32(%rsi)
    rmmovq %r12, 40(%rsi)
    rmmovq %r13, 48(%rsi)
    rmmovq %r14, 56(%rsi)
    rmmovq %rbx, 64(%rsi)


    andq %rcx,%rcx
	jle notInc1
	iaddq $1,%rax

notInc1:
    andq %r8,%r8
	jle notInc2
	iaddq $1,%rax

notInc2:
    andq %r9,%r9
	jle notInc3
	iaddq $1,%rax

notInc3:
    andq %r10,%r10
	jle notInc4
	iaddq $1,%rax

notInc4:
    andq %r11,%r11 # val <= 0?
	jle notInc5
	iaddq $1,%rax

notInc5:
    andq %r12,%r12 # val <= 0?
	jle notInc6
	iaddq $1,%rax

notInc6:
    andq %r13,%r13 # val <= 0?
	jle notInc7
	iaddq $1,%rax

notInc7:
    andq %r14,%r14 # val <= 0?
	jle notInc8
	iaddq $1,%rax

notInc8:
    andq %rbx,%rbx # val <= 0?
	jle notInc9
	iaddq $1,%rax

notInc9:
	iaddq $72, %rdi		# src+=6
	iaddq $72, %rsi		# dst+=6
	iaddq $-9, %rdx		# len-=6 # len >= 0?
	jge Loop			# if so, goto Loop:

end:
    iaddq $9,%rdx
    je Done

#1
    mrmovq (%rdi), %rcx
    rmmovq %rcx, (%rsi)
    andq %rcx,%rcx # val <= 0?
	jle notIncx9
	iaddq $1,%rax
notIncx9:
    iaddq $-1,%rdx
    je Done
#2
    mrmovq 8(%rdi), %r8
    rmmovq %r8, 8(%rsi)
    andq %r8,%r8
	jle notIncx10
	iaddq $1,%rax
notIncx10:

# ...and store it to dst
    iaddq $-1,%rdx
    je Done

#3
    mrmovq 16(%rdi), %r9
    rmmovq %r9, 16(%rsi)
    andq %r9,%r9
	jle notIncx11
	iaddq $1,%rax
notIncx11:
    iaddq $-1,%rdx
    je Done
#4
    mrmovq 24(%rdi), %r10
    rmmovq %r10, 24(%rsi)
    andq %r10,%r10
	jle notIncx12
	iaddq $1,%rax
notIncx12:
#5
    iaddq $-1,%rdx
    je Done
    mrmovq 32(%rdi), %rcx	
    rmmovq %rcx, 32(%rsi)
    andq %rcx,%rcx
    jle notIncx13
    iaddq $1,%rax
notIncx13:
#6
    iaddq $-1,%rdx
    je Done
    mrmovq 40(%rdi), %rcx	
    rmmovq %rcx, 40(%rsi)
    andq %rcx,%rcx
    jle notIncx14
    iaddq $1,%rax
notIncx14:
#7
    iaddq $-1,%rdx
    je Done
    mrmovq 48(%rdi), %rcx	
    rmmovq %rcx, 48(%rsi)
    andq %rcx,%rcx
    jle notIncx15
    iaddq $1,%rax
notIncx15:
#8
    iaddq $-1,%rdx
    je Done
    mrmovq 56(%rdi), %rcx	
    rmmovq %rcx, 56(%rsi)
    andq %rcx,%rcx
    jle Done
    iaddq $1,%rax

##################################################################
# Do not modify the following section of code
# Function epilogue.
Done:
	ret
##################################################################
# Keep the following label at the end of your function
End:
#/* $end ncopy-ys */
EndFun:

###############################
# Source and destination blocks 
###############################
	.align 8
src:
	.quad -1
	.quad -2
	.quad -3
	.quad 4
	.quad -5
	.quad -6
	.quad 7
	.quad 8
	.quad -9
	.quad 10
	.quad 11
	.quad 12
	.quad 13
	.quad 14
	.quad 15
	.quad -16
	.quad 17
	.quad -18
	.quad -19
	.quad 20
	.quad 21
	.quad -22
	.quad 23
	.quad -24
	.quad 25
	.quad -26
	.quad -27
	.quad -28
	.quad -29
	.quad -30
	.quad 31
	.quad -32
	.quad 33
	.quad 34
	.quad 35
	.quad 36
	.quad 37
	.quad 38
	.quad -39
	.quad -40
	.quad 41
	.quad 42
	.quad -43
	.quad 44
	.quad 45
	.quad -46
	.quad -47
	.quad 48
	.quad 49
	.quad -50
	.quad -51
	.quad -52
	.quad 53
	.quad 54
	.quad 55
	.quad -56
	.quad -57
	.quad 58
	.quad -59
	.quad -60
	.quad -61
	.quad -62
	.quad -63
	.quad 0xbcdefa # This shouldn't get moved

	.align 16
Predest:
	.quad 0xbcdefa
dest:
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
	.quad 0xcdefab
Postdest:
	.quad 0xdefabc

.align 8
# Run time stack
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0
	.quad 0

Stack:
